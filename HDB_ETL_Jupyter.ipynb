{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-7873080754854529896",
   "metadata": {},
   "source": [
    "# HDB Resale Flat Prices ‚Äî ETL Pipeline\n",
    "\n",
    "This notebook runs the full end-to-end ETL pipeline for HDB resale flat prices (Mar 2012 ‚Äì Dec 2016).\n",
    "\n",
    "### Pipeline Stages\n",
    "| Stage | Description |\n",
    "|-------|-------------|\n",
    "| **0. Download** | Fetch raw CSVs from data.gov.sg via API |\n",
    "| **1. Load** | Read and align both CSV snapshots |\n",
    "| **2. Clean** | Type casting, null drops, lease recomputation |\n",
    "| **3. Deduplicate** | Remove duplicate records, save audit file |\n",
    "| **4. Validate** | Apply business rules, flag violations |\n",
    "| **5. Anomaly Detection** | 3-sigma price outlier detection per town/flat type |\n",
    "| **6. Profile** | Statistical summary of cleaned dataset |\n",
    "| **7. Transform** | Create synthetic Resale Identifier |\n",
    "| **8. Hash** | SHA-256 hash the Resale Identifier |\n",
    "\n",
    "> **Prerequisites:** Ensure `download_hdb_data.py` is in the same folder as this notebook.\n",
    "> Install dependencies: `pip install pandas requests`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-3283083262286261220",
   "metadata": {},
   "source": [
    "## Stage 0 ‚Äî Download Raw Data\n",
    "\n",
    "> **How this works:** `%run` executes `download_hdb_data.py` directly inside the notebook kernel,\n",
    "> so all `print()` output appears here in real time.\n",
    "\n",
    "> **Requirement:** `download_hdb_data.py` must be in the **same folder** as this notebook.\n",
    "\n",
    "The script will:\n",
    "1. Connect to the data.gov.sg API\n",
    "2. Auto-discover matching datasets by keyword\n",
    "3. Download both CSV files into the `hdb_data/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "code-971733223855965915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì download_hdb_data.py found ‚Äî starting download...\n",
      "============================================================\n",
      "============================================================\n",
      "HDB Resale Flat Prices ‚Äî Auto-discover & Download\n",
      "============================================================\n",
      "Fetching collection metadata...\n",
      "Found 5 datasets in collection. Fetching names...\n",
      "\n",
      "  d_8b84c4ee58e3cfc0ece0d773c8ca6abc ‚Üí Resale flat prices based on registration date from Jan-2017 onwards\n",
      "  d_43f493c6c50d54243cc1eab0df142d6a ‚Üí Resale Flat Prices (Based on Approval Date), 2000 - Feb 2012\n",
      "  d_2d5ff9ea31397b66239f245f57751537 ‚Üí Resale Flat Prices (Based on Registration Date), From Mar 2012 to Dec 2014\n",
      "  d_ebc5ab87086db484f88045b47411ebc5 ‚Üí Resale Flat Prices (Based on Approval Date), 1990 - 1999\n",
      "  d_ea9ed51da2787afaf8e51f827c304208 ‚Üí Resale Flat Prices (Based on Registration Date), From Jan 2015 to Dec 2016\n",
      "\n",
      "  Matched: [Registration Date, Mar 2012, Dec 2014] ‚Üí Resale Flat Prices (Based on Registration Date), From Mar 2012 to Dec 2014\n",
      "  Matched: [Registration Date, Jan 2015, Dec 2016] ‚Üí Resale Flat Prices (Based on Registration Date), From Jan 2015 to Dec 2016\n",
      "\n",
      "Downloading 2 matched dataset(s)...\n",
      "\n",
      "============================================================\n",
      "\n",
      "[1/2] Resale Flat Prices (Based on Registration Date), From Mar 2012 to Dec 2014\n",
      "  Initiating download...\n",
      "  Polling for download URL...\n",
      "    Rate limited. Waiting 10s (retry 1/6)...\n",
      "  URL ready.\n",
      "  Downloading...\n",
      "  Saved: hdb_data\\Resale_Flat_Prices_Based_on_Registration_Date_From_Mar_2012_to_Dec_2014.csv (4063.3 KB)\n",
      "\n",
      "  Pausing 15s before next download...\n",
      "\n",
      "[2/2] Resale Flat Prices (Based on Registration Date), From Jan 2015 to Dec 2016\n",
      "  Initiating download...\n",
      "  Polling for download URL...\n",
      "    Rate limited. Waiting 10s (retry 1/6)...\n",
      "  URL ready.\n",
      "  Downloading...\n",
      "  Saved: hdb_data\\Resale_Flat_Prices_Based_on_Registration_Date_From_Jan_2015_to_Dec_2016.csv (2998.9 KB)\n",
      "\n",
      "============================================================\n",
      "Done! Files saved in './hdb_data/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ‚îÄ‚îÄ Preflight check ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "DOWNLOADER = 'download_hdb_data.py'\n",
    "\n",
    "if not os.path.isfile(DOWNLOADER):\n",
    "    raise FileNotFoundError(\n",
    "        f\"'{DOWNLOADER}' not found in '{os.getcwd()}'.\\n\"\n",
    "        f\"Please copy download_hdb_data.py into the same folder as this notebook.\"\n",
    "    )\n",
    "\n",
    "print(f'‚úì {DOWNLOADER} found ‚Äî starting download...')\n",
    "print('=' * 60)\n",
    "\n",
    "# ‚îÄ‚îÄ Run downloader in-kernel so all output is visible ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "%run download_hdb_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "code-6428715373487472338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking downloaded files...\n",
      "  ‚úì hdb_data\\Resale_Flat_Prices_Based_on_Registration_Date_From_Mar_2012_to_Dec_2014.csv  (4063.3 KB)\n",
      "  ‚úì hdb_data\\Resale_Flat_Prices_Based_on_Registration_Date_From_Jan_2015_to_Dec_2016.csv  (2998.9 KB)\n",
      "\n",
      "‚úÖ All files present ‚Äî safe to proceed to Stage 1.\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Verify downloaded files exist before proceeding ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EXPECTED_FILES = [\n",
    "    os.path.join('hdb_data', 'Resale_Flat_Prices_Based_on_Registration_Date_From_Mar_2012_to_Dec_2014.csv'),\n",
    "    os.path.join('hdb_data', 'Resale_Flat_Prices_Based_on_Registration_Date_From_Jan_2015_to_Dec_2016.csv'),\n",
    "]\n",
    "\n",
    "print('Checking downloaded files...')\n",
    "all_found = True\n",
    "for f in EXPECTED_FILES:\n",
    "    if os.path.isfile(f):\n",
    "        size_kb = os.path.getsize(f) / 1024\n",
    "        print(f'  ‚úì {f}  ({size_kb:.1f} KB)')\n",
    "    else:\n",
    "        print(f'  ‚ùå MISSING: {f}')\n",
    "        all_found = False\n",
    "\n",
    "if not all_found:\n",
    "    raise RuntimeError('Some files are missing. Re-run the download cell above before continuing.')\n",
    "else:\n",
    "    print('\\n‚úÖ All files present ‚Äî safe to proceed to Stage 1.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-1661948964046021057",
   "metadata": {},
   "source": [
    "## Stage 1 ‚Äî Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "code-672414232777651006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print('‚úì Libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "code-7808428785612355360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Output directories created\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Output directories ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "RAW_DIR          = 'hdb_data'\n",
    "OUTPUT_DIR       = 'output'\n",
    "RAW_OUT_DIR      = os.path.join(OUTPUT_DIR, 'raw')\n",
    "CLEANED_OUT_DIR  = os.path.join(OUTPUT_DIR, 'cleaned')\n",
    "TRANSFORM_OUT_DIR= os.path.join(OUTPUT_DIR, 'transformed')\n",
    "HASHED_OUT_DIR   = os.path.join(OUTPUT_DIR, 'hashed')\n",
    "FAILED_OUT_DIR   = os.path.join(OUTPUT_DIR, 'failed')\n",
    "AUDIT_OUT_DIR    = os.path.join(OUTPUT_DIR, 'audit')\n",
    "PROFILE_OUT_DIR  = os.path.join(OUTPUT_DIR, 'profiling')\n",
    "\n",
    "for d in [RAW_OUT_DIR, CLEANED_OUT_DIR, TRANSFORM_OUT_DIR,\n",
    "          HASHED_OUT_DIR, FAILED_OUT_DIR, AUDIT_OUT_DIR, PROFILE_OUT_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print('‚úì Output directories created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "code-6755739720814924498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì CSV paths configured\n",
      "  ‚úì Found: hdb_data\\Resale_Flat_Prices_Based_on_Registration_Date_From_Mar_2012_to_Dec_2014.csv\n",
      "  ‚úì Found: hdb_data\\Resale_Flat_Prices_Based_on_Registration_Date_From_Jan_2015_to_Dec_2016.csv\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Input CSV files ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "CSV_FILES = [\n",
    "    'Resale_Flat_Prices_Based_on_Registration_Date_From_Mar_2012_to_Dec_2014.csv',\n",
    "    'Resale_Flat_Prices_Based_on_Registration_Date_From_Jan_2015_to_Dec_2016.csv'\n",
    "]\n",
    "CSV_PATHS = [os.path.join(RAW_DIR, f) for f in CSV_FILES]\n",
    "\n",
    "EXPECTED_START = pd.Period('2012-03', freq='M')\n",
    "EXPECTED_END   = pd.Period('2016-12', freq='M')\n",
    "\n",
    "print('‚úì CSV paths configured')\n",
    "for p in CSV_PATHS:\n",
    "    exists = '‚úì Found' if os.path.isfile(p) else '‚ùå Missing'\n",
    "    print(f'  {exists}: {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "code-4053748763826909990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Validation sets loaded: 26 towns, 7 flat types, 20 flat models\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Validation reference sets ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "VALID_TOWNS = {\n",
    "    'ANG MO KIO','BEDOK','BISHAN','BUKIT BATOK','BUKIT MERAH',\n",
    "    'BUKIT PANJANG','BUKIT TIMAH','CENTRAL AREA','CHOA CHU KANG','CLEMENTI',\n",
    "    'GEYLANG','HOUGANG','JURONG EAST','JURONG WEST','KALLANG/WHAMPOA',\n",
    "    'MARINE PARADE','PASIR RIS','PUNGGOL','QUEENSTOWN','SEMBAWANG',\n",
    "    'SENGKANG','SERANGOON','TAMPINES','TOA PAYOH','WOODLANDS','YISHUN'\n",
    "}\n",
    "\n",
    "VALID_FLAT_TYPES = {'1 ROOM','2 ROOM','3 ROOM','4 ROOM','5 ROOM','EXECUTIVE','MULTI-GENERATION'}\n",
    "\n",
    "VALID_FLAT_MODELS = {\n",
    "    '2-room','Adjoined flat','Apartment','DBSS','Improved','Improved-Maisonette',\n",
    "    'Maisonette','Model A','Model A2','Model A-Maisonette','Multi Generation',\n",
    "    'New Generation','Premium Apartment','Premium Apartment Loft','Premium Maisonette',\n",
    "    'Simplified','Standard','Terrace','Type S1','Type S2'\n",
    "}\n",
    "\n",
    "VALID_STOREY_FORMAT = r'^\\d{2} TO \\d{2}$'\n",
    "\n",
    "print(f'‚úì Validation sets loaded: {len(VALID_TOWNS)} towns, {len(VALID_FLAT_TYPES)} flat types, {len(VALID_FLAT_MODELS)} flat models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-3574869889449696156",
   "metadata": {},
   "source": [
    "## Stage 2 ‚Äî Load & Align Raw Snapshots\n",
    "\n",
    "Reads both CSV files and aligns their columns (via `reindex`) before concatenating into one master DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "code-8903133000836065713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading and aligning CSV snapshots...\n",
      "   - hdb_data\\Resale_Flat_Prices_Based_on_Registration_Date_From_Mar_2012_to_Dec_2014.csv\n",
      "     ‚Üí 52,203 rows, 10 columns\n",
      "   - hdb_data\\Resale_Flat_Prices_Based_on_Registration_Date_From_Jan_2015_to_Dec_2016.csv\n",
      "     ‚Üí 37,153 rows, 11 columns\n",
      "‚è± Load & Align CSVs executed in 0.15s\n",
      "üíæ Raw dataset saved: output\\raw\\hdb_resale_raw.csv\n",
      "\n",
      "Shape: 89,356 rows √ó 11 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>month</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>street_name</th>\n",
       "      <th>town</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172</td>\n",
       "      <td>Improved</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>2012-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>06 TO 10</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>510</td>\n",
       "      <td>Improved</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1980</td>\n",
       "      <td>2012-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>01 TO 05</td>\n",
       "      <td>ANG MO KIO AVE 8</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>610</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1980</td>\n",
       "      <td>2012-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>06 TO 10</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  block      flat_model flat_type  floor_area_sqm  lease_commence_date  \\\n",
       "0   172        Improved    2 ROOM            45.0                 1986   \n",
       "1   510        Improved    2 ROOM            44.0                 1980   \n",
       "2   610  New Generation    3 ROOM            68.0                 1980   \n",
       "\n",
       "     month  remaining_lease  resale_price storey_range       street_name  \\\n",
       "0  2012-03              NaN      250000.0     06 TO 10  ANG MO KIO AVE 4   \n",
       "1  2012-03              NaN      265000.0     01 TO 05  ANG MO KIO AVE 8   \n",
       "2  2012-03              NaN      315000.0     06 TO 10  ANG MO KIO AVE 4   \n",
       "\n",
       "         town  \n",
       "0  ANG MO KIO  \n",
       "1  ANG MO KIO  \n",
       "2  ANG MO KIO  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def timed_step(name, func, *args, **kwargs):\n",
    "    start = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    elapsed = time.time() - start\n",
    "    print(f'‚è± {name} executed in {elapsed:.2f}s')\n",
    "    return result\n",
    "\n",
    "def load_and_align_snapshots():\n",
    "    print('üì¶ Loading and aligning CSV snapshots...')\n",
    "    dfs = []\n",
    "    for path in CSV_PATHS:\n",
    "        print(f'   - {path}')\n",
    "        df = pd.read_csv(path)\n",
    "        print(f'     ‚Üí {len(df):,} rows, {len(df.columns)} columns')\n",
    "        dfs.append(df)\n",
    "    all_columns = sorted(set().union(*(df.columns for df in dfs)))\n",
    "    aligned_dfs = [df.reindex(columns=all_columns) for df in dfs]\n",
    "    master_df = pd.concat(aligned_dfs, ignore_index=True)\n",
    "    return master_df\n",
    "\n",
    "df = timed_step('Load & Align CSVs', load_and_align_snapshots)\n",
    "\n",
    "raw_file = os.path.join(RAW_OUT_DIR, 'hdb_resale_raw.csv')\n",
    "df.to_csv(raw_file, index=False)\n",
    "print(f'üíæ Raw dataset saved: {raw_file}')\n",
    "print(f'\\nShape: {df.shape[0]:,} rows √ó {df.shape[1]} columns')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-4961381224581248120",
   "metadata": {},
   "source": [
    "## Stage 3 ‚Äî Data Cleaning\n",
    "\n",
    "- Cast `month`, `resale_price`, `floor_area_sqm` to correct types\n",
    "- Drop rows with nulls in critical fields\n",
    "- Recompute `remaining_lease` from `lease_commence_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "code-7224205749141854025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Type casting complete\n",
      "  Rows dropped (null critical fields): 0\n",
      "  Rows remaining: 89,356\n"
     ]
    }
   ],
   "source": [
    "# Type casting\n",
    "df['month']          = pd.to_datetime(df['month'], format='%Y-%m', errors='coerce')\n",
    "df['resale_price']   = pd.to_numeric(df['resale_price'], errors='coerce')\n",
    "df['floor_area_sqm'] = pd.to_numeric(df['floor_area_sqm'], errors='coerce')\n",
    "\n",
    "before = len(df)\n",
    "df = df.dropna(subset=['month', 'resale_price', 'floor_area_sqm'])\n",
    "after = len(df)\n",
    "print(f'‚úì Type casting complete')\n",
    "print(f'  Rows dropped (null critical fields): {before - after:,}')\n",
    "print(f'  Rows remaining: {after:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "code-5373970644915005147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì remaining_lease recomputed\n",
      "  Sample values:\n",
      " lease_commence_date    remaining_lease\n",
      "                1986 58 years 11 months\n",
      "                1980 52 years 11 months\n",
      "                1984 56 years 11 months\n",
      "                1981 53 years 11 months\n",
      "                1978 50 years 11 months\n"
     ]
    }
   ],
   "source": [
    "def recompute_remaining_lease(df):\n",
    "    today = pd.Timestamp.today()\n",
    "    def compute(row):\n",
    "        lease_start = row.get('lease_commence_date')\n",
    "        if pd.isna(lease_start):\n",
    "            return None\n",
    "        end = pd.Timestamp(year=int(lease_start), month=1, day=1) + pd.DateOffset(years=99)\n",
    "        if end < today:\n",
    "            return '0 years 0 months'\n",
    "        months_remaining = (end.year - today.year) * 12 + (end.month - today.month)\n",
    "        return f'{months_remaining//12} years {months_remaining%12} months'\n",
    "    df['remaining_lease'] = df.apply(compute, axis=1)\n",
    "    return df\n",
    "\n",
    "df = recompute_remaining_lease(df)\n",
    "print('‚úì remaining_lease recomputed')\n",
    "print(f'  Sample values:')\n",
    "print(df[['lease_commence_date','remaining_lease']].drop_duplicates().head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-7590685506075398090",
   "metadata": {},
   "source": [
    "## Stage 4 ‚Äî Deduplication\n",
    "\n",
    "Identifies duplicate records where all fields except `resale_price` are identical.\n",
    "Keeps the row with the **higher** price and saves removed duplicates to audit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "code-3692723629831264241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Deduplication complete\n",
      "  Original rows : 89,356\n",
      "  Duplicates    : 1,560\n",
      "  Clean rows    : 87,796\n",
      "  ‚ö†Ô∏è  Duplicates saved: output\\audit\\duplicates.csv\n"
     ]
    }
   ],
   "source": [
    "def deduplicate_dataset(df):\n",
    "    key_cols = [c for c in df.columns if c != 'resale_price']\n",
    "    df_sorted  = df.sort_values('resale_price', ascending=False)\n",
    "    df_cleaned = df_sorted.drop_duplicates(subset=key_cols, keep='first')\n",
    "    df_dupes   = df_sorted.loc[~df_sorted.index.isin(df_cleaned.index)]\n",
    "    return df_cleaned, df_dupes\n",
    "\n",
    "df_cleaned, df_duplicates = deduplicate_dataset(df)\n",
    "\n",
    "print(f'‚úì Deduplication complete')\n",
    "print(f'  Original rows : {len(df):,}')\n",
    "print(f'  Duplicates    : {len(df_duplicates):,}')\n",
    "print(f'  Clean rows    : {len(df_cleaned):,}')\n",
    "\n",
    "if not df_duplicates.empty:\n",
    "    path = os.path.join(AUDIT_OUT_DIR, 'duplicates.csv')\n",
    "    df_duplicates.to_csv(path, index=False)\n",
    "    print(f'  ‚ö†Ô∏è  Duplicates saved: {path}')\n",
    "else:\n",
    "    print('  ‚úì No duplicates found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-1337146713984008264",
   "metadata": {},
   "source": [
    "## Stage 5 ‚Äî Business Rule Validation\n",
    "\n",
    "Applies 6 domain-specific rules row by row. Any failing row is captured with a `comments` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "code-5713787363207121854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Validation complete\n",
      "  Rule violations : 0 rows\n",
      "  ‚úì No rule violations found\n"
     ]
    }
   ],
   "source": [
    "def extra_validation(df):\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        issues = []\n",
    "       \n",
    "        # 1. Validate resale_price\n",
    "        if r.get('resale_price',0) <= 0:\n",
    "            issues.append(\"invalid resale_price\")\n",
    "\n",
    "        # 2. Validate floor_area_sqm \t\n",
    "        if r.get('floor_area_sqm',0) <= 0 or r.get('floor_area_sqm',0) > 500:\n",
    "            issues.append(\"invalid floor_area_sqm\")\n",
    "\n",
    "        # 3. Validate town\n",
    "        if r.get('town') not in VALID_TOWNS:\n",
    "            issues.append(\"invalid town\")\n",
    "\n",
    "        # 4. Validate flat_type\n",
    "        if r.get('flat_type') not in VALID_FLAT_TYPES:\n",
    "            issues.append(\"invalid flat_type\")\n",
    "\n",
    "        # 5. Validate flat_model\n",
    "        if r.get('flat_model') not in VALID_FLAT_MODELS:\n",
    "            issues.append(\"invalid flat_model\")\n",
    "\n",
    "        # 6. Validate storey_range format (e.g. \"01 TO 03\")\n",
    "        if not re.match(VALID_STOREY_FORMAT, str(r.get('storey_range'))):\n",
    "            issues.append(\"invalid storey_range\")\n",
    "\n",
    "        # 7. Validate month ‚Äî must be within Mar 2012 to Dec 2016 (year + month check)\n",
    "        month_val = r.get('month')\n",
    "        if pd.isna(month_val):\n",
    "            issues.append(\"missing month\")\n",
    "        else:\n",
    "            month_period = pd.Period(month_val, freq=\"M\")\n",
    "            if month_period < EXPECTED_START or month_period > EXPECTED_END:\n",
    "                issues.append(f\"month out of range: {month_period} (expected {EXPECTED_START} to {EXPECTED_END})\")\n",
    "                \n",
    "        if issues:\n",
    "            row_copy = r.copy()\n",
    "            row_copy['comments'] = '; '.join(issues)\n",
    "            rows.append(row_copy)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_rules_fail = extra_validation(df_cleaned)\n",
    "\n",
    "print(f'‚úì Validation complete')\n",
    "print(f'  Rule violations : {len(df_rules_fail):,} rows')\n",
    "\n",
    "if not df_rules_fail.empty:\n",
    "    path = os.path.join(AUDIT_OUT_DIR, 'rule_violations.csv')\n",
    "    df_rules_fail.to_csv(path, index=False)\n",
    "    print(f'  ‚ö†Ô∏è  Violations saved: {path}')\n",
    "    print(df_rules_fail['comments'].value_counts().head(10))\n",
    "else:\n",
    "    print('  ‚úì No rule violations found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-6768001129970658899",
   "metadata": {},
   "source": [
    "## Stage 6 ‚Äî Anomaly Detection (3-Sigma)\n",
    "\n",
    "Detects statistically unusual resale prices using the **3-sigma (Z-score) method**.\n",
    "\n",
    "### Why 3-Sigma?\n",
    "Based on the Empirical Rule (68-95-99.7 Rule):\n",
    "\n",
    "| Sigma | Data Coverage | Frequency | Decision |\n",
    "|-------|--------------|-----------|----------|\n",
    "| 1œÉ | ~68% | 1 in 3 | Too sensitive |\n",
    "| 2œÉ | ~95% | 1 in 20 | Too many false positives |\n",
    "| **3œÉ** | **~99.7%** | **1 in 370** | **Selected threshold ‚úì** |\n",
    "\n",
    "### Why localised grouping (per Town + Flat Type)?\n",
    "Each flat is compared only against its own peer group (same town, same flat type) ‚Äî\n",
    "so a \\$900k Executive flat is never unfairly penalised for being more expensive than a 3-room flat next door.\n",
    "\n",
    "> **Assumption:** Prices within each Town + Flat Type group are approximately normally distributed.\n",
    "> If heavily skewed, consider Median Absolute Deviation (MAD) as a more robust alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "code-6969248881697908207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Anomaly detection complete\n",
      "  Anomalous rows: 450\n",
      "  ‚ö†Ô∏è  Anomalies saved: output\\audit\\anomalies.csv\n",
      "\n",
      "  Top anomalous towns:\n",
      "town\n",
      "BEDOK              72\n",
      "TAMPINES           46\n",
      "KALLANG/WHAMPOA    42\n",
      "ANG MO KIO         31\n",
      "HOUGANG            31\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def detect_anomalous_prices(df):\n",
    "    df = df.copy()\n",
    "    df['price_anomaly'] = False\n",
    "    anomalies_list = []\n",
    "\n",
    "    for (town, flat_type), group in df.groupby(['town', 'flat_type']):\n",
    "        if len(group) < 3:  # Skip groups too small for meaningful std\n",
    "            continue\n",
    "        mean  = group['resale_price'].mean()\n",
    "        std   = group['resale_price'].std()\n",
    "        lower = mean - 3 * std\n",
    "        upper = mean + 3 * std\n",
    "        anomalies = group[(group['resale_price'] < lower) | (group['resale_price'] > upper)]\n",
    "        if not anomalies.empty:\n",
    "            df.loc[anomalies.index, 'price_anomaly'] = True\n",
    "            anomalies_list.append(anomalies)\n",
    "\n",
    "    return pd.concat(anomalies_list) if anomalies_list else pd.DataFrame()\n",
    "\n",
    "df_anomalies = detect_anomalous_prices(df_cleaned)\n",
    "\n",
    "print(f'‚úì Anomaly detection complete')\n",
    "print(f'  Anomalous rows: {len(df_anomalies):,}')\n",
    "\n",
    "if not df_anomalies.empty:\n",
    "    path = os.path.join(AUDIT_OUT_DIR, 'anomalies.csv')\n",
    "    df_anomalies.to_csv(path, index=False)\n",
    "    print(f'  ‚ö†Ô∏è  Anomalies saved: {path}')\n",
    "    print('\\n  Top anomalous towns:')\n",
    "    print(df_anomalies['town'].value_counts().head(5))\n",
    "else:\n",
    "    print('  ‚úì No anomalies detected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-7208711213571599069",
   "metadata": {},
   "source": [
    "## Stage 6b ‚Äî Combine Failed Records & Finalise Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "code-1683713986782011038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total failed records (dupes + violations + anomalies): 2,008\n",
      "  ‚ö†Ô∏è  Failed records saved: output\\failed\\hdb_resale_failed.csv\n",
      "\n",
      "üíæ Cleaned dataset saved: output\\cleaned\\hdb_resale_cleaned.csv\n",
      "   Final rows: 87,346\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>month</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>street_name</th>\n",
       "      <th>town</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83511</th>\n",
       "      <td>1G</td>\n",
       "      <td>Type S2</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>83 years 11 months</td>\n",
       "      <td>1120000.0</td>\n",
       "      <td>43 TO 45</td>\n",
       "      <td>CANTONMENT RD</td>\n",
       "      <td>CENTRAL AREA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86801</th>\n",
       "      <td>1D</td>\n",
       "      <td>Type S2</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>83 years 11 months</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>46 TO 48</td>\n",
       "      <td>CANTONMENT RD</td>\n",
       "      <td>CENTRAL AREA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86800</th>\n",
       "      <td>1B</td>\n",
       "      <td>Type S2</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>83 years 11 months</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>31 TO 33</td>\n",
       "      <td>CANTONMENT RD</td>\n",
       "      <td>CENTRAL AREA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      block flat_model flat_type  floor_area_sqm  lease_commence_date  \\\n",
       "83511    1G    Type S2    5 ROOM           106.0                 2011   \n",
       "86801    1D    Type S2    5 ROOM           107.0                 2011   \n",
       "86800    1B    Type S2    5 ROOM           106.0                 2011   \n",
       "\n",
       "           month     remaining_lease  resale_price storey_range  \\\n",
       "83511 2016-09-01  83 years 11 months     1120000.0     43 TO 45   \n",
       "86801 2016-11-01  83 years 11 months     1100000.0     46 TO 48   \n",
       "86800 2016-11-01  83 years 11 months     1100000.0     31 TO 33   \n",
       "\n",
       "         street_name          town  \n",
       "83511  CANTONMENT RD  CENTRAL AREA  \n",
       "86801  CANTONMENT RD  CENTRAL AREA  \n",
       "86800  CANTONMENT RD  CENTRAL AREA  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all failed records\n",
    "failed_records = pd.concat([df_duplicates, df_rules_fail, df_anomalies]).drop_duplicates()\n",
    "print(f'Total failed records (dupes + violations + anomalies): {len(failed_records):,}')\n",
    "\n",
    "if not failed_records.empty:\n",
    "    path = os.path.join(FAILED_OUT_DIR, 'hdb_resale_failed.csv')\n",
    "    failed_records.to_csv(path, index=False)\n",
    "    print(f'  ‚ö†Ô∏è  Failed records saved: {path}')\n",
    "\n",
    "# Remove failed from cleaned\n",
    "df_cleaned_final = df_cleaned.loc[~df_cleaned.index.isin(failed_records.index)]\n",
    "cleaned_file = os.path.join(CLEANED_OUT_DIR, 'hdb_resale_cleaned.csv')\n",
    "df_cleaned_final.to_csv(cleaned_file, index=False)\n",
    "\n",
    "print(f'\\nüíæ Cleaned dataset saved: {cleaned_file}')\n",
    "print(f'   Final rows: {len(df_cleaned_final):,}')\n",
    "df_cleaned_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-6348223152617364229",
   "metadata": {},
   "source": [
    "## Stage 7 ‚Äî Data Profiling\n",
    "\n",
    "Generates a statistical summary of the cleaned dataset including null counts, numeric distributions, and duplicate counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "code-2489465299007983501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è± Profile Cleaned Dataset executed in 0.12s\n",
      "üìä Profiling report saved: output\\profiling\\profile_cleaned.csv\n",
      "\n",
      "‚îÄ‚îÄ Key Statistics ‚îÄ‚îÄ\n",
      "  Rows          : 87,346\n",
      "  Columns       : 11\n",
      "  Duplicates    : 0\n",
      "  Price min     : $192,000\n",
      "  Price max     : $1,120,000\n",
      "  Price mean    : $450,913\n",
      "  Price median  : $428,000\n"
     ]
    }
   ],
   "source": [
    "def profile_dataset(df):\n",
    "    profile = {}\n",
    "    profile['total_rows']    = len(df)\n",
    "    profile['total_columns'] = len(df.columns)\n",
    "    profile.update({f'null_count_{col}': df[col].isna().sum() for col in df.columns})\n",
    "    for col in ['resale_price', 'floor_area_sqm']:\n",
    "        if col in df.columns:\n",
    "            profile[f'{col}_min']    = df[col].min()\n",
    "            profile[f'{col}_max']    = df[col].max()\n",
    "            profile[f'{col}_mean']   = df[col].mean()\n",
    "            profile[f'{col}_median'] = df[col].median()\n",
    "    profile['duplicate_rows'] = df.duplicated().sum()\n",
    "    return profile\n",
    "\n",
    "profile = timed_step('Profile Cleaned Dataset', profile_dataset, df_cleaned_final)\n",
    "profile_df = pd.DataFrame([profile])\n",
    "\n",
    "path = os.path.join(PROFILE_OUT_DIR, 'profile_cleaned.csv')\n",
    "profile_df.to_csv(path, index=False)\n",
    "print(f'üìä Profiling report saved: {path}')\n",
    "\n",
    "# Display key stats\n",
    "print('\\n‚îÄ‚îÄ Key Statistics ‚îÄ‚îÄ')\n",
    "print(f\"  Rows          : {profile['total_rows']:,}\")\n",
    "print(f\"  Columns       : {profile['total_columns']}\")\n",
    "print(f\"  Duplicates    : {profile['duplicate_rows']}\")\n",
    "print(f\"  Price min     : ${profile['resale_price_min']:,.0f}\")\n",
    "print(f\"  Price max     : ${profile['resale_price_max']:,.0f}\")\n",
    "print(f\"  Price mean    : ${profile['resale_price_mean']:,.0f}\")\n",
    "print(f\"  Price median  : ${profile['resale_price_median']:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-28820051034802207",
   "metadata": {},
   "source": [
    "## Stage 8 ‚Äî Transformation: Resale Identifier\n",
    "\n",
    "Creates a synthetic `Resale Identifier` field encoding location, price context, and timing:\n",
    "\n",
    "```\n",
    "Format:  S + block_numeric(3) + avg_price_prefix(2) + month_num(2) + town_initial(1)\n",
    "Example: S042450303A\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "code-6995343723949094473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Transformed dataset saved: output\\transformed\\hdb_resale_transformed.csv\n",
      "\n",
      "Sample Resale Identifiers:\n",
      "        town flat_type  resale_price Resale Identifier\n",
      "CENTRAL AREA    5 ROOM     1120000.0         S0011009C\n",
      "CENTRAL AREA    5 ROOM     1100000.0         S0011011C\n",
      "CENTRAL AREA    5 ROOM     1100000.0         S0011011C\n",
      "CENTRAL AREA    5 ROOM     1088000.0         S0019311C\n",
      "CENTRAL AREA    5 ROOM     1070000.0         S0011008C\n"
     ]
    }
   ],
   "source": [
    "def create_resale_identifier(df):\n",
    "    df_copy = df.copy()\n",
    "    if 'block' not in df_copy.columns:\n",
    "        df_copy['block'] = '000'\n",
    "    df_copy['block_numeric'] = (\n",
    "        df_copy['block'].astype(str)\n",
    "        .str.extract(r'(\\d+)')[0]\n",
    "        .fillna('000')\n",
    "        .str.zfill(3)\n",
    "    )\n",
    "    df_copy['year_month'] = df_copy['month'].dt.to_period('M')\n",
    "    avg_price = df_copy.groupby(['year_month','town','flat_type'])['resale_price'].transform('mean')\n",
    "    df_copy['Resale Identifier'] = (\n",
    "        'S' +\n",
    "        df_copy['block_numeric'] +\n",
    "        avg_price.astype(int).astype(str).str[:2] +\n",
    "        df_copy['month'].dt.month.astype(str).str.zfill(2) +\n",
    "        df_copy['town'].str[0]\n",
    "    )\n",
    "    return df_copy\n",
    "\n",
    "df_transformed = create_resale_identifier(df_cleaned_final)\n",
    "\n",
    "path = os.path.join(TRANSFORM_OUT_DIR, 'hdb_resale_transformed.csv')\n",
    "df_transformed.to_csv(path, index=False)\n",
    "print(f'üíæ Transformed dataset saved: {path}')\n",
    "print('\\nSample Resale Identifiers:')\n",
    "print(df_transformed[['town','flat_type','resale_price','Resale Identifier']].head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-8035671662094914602",
   "metadata": {},
   "source": [
    "## Stage 9 ‚Äî Hashing\n",
    "\n",
    "Applies **SHA-256** hashing to the `Resale Identifier` field, producing `Resale Identifier Hashed`.\n",
    "\n",
    "- Anonymises the synthetic key while preserving uniqueness\n",
    "- Deterministic: same input always produces the same 64-character hex output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "code-1111392567481699851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Hashed dataset saved: output\\hashed\\hdb_resale_hashed.csv\n",
      "\n",
      "Sample hashes:\n",
      "Resale Identifier                                         Resale Identifier Hashed\n",
      "        S0011009C dc3cb88029cf26ce1e87b42904bcd0b6eb033a6ebc5f806d36f88a45aa38cb6c\n",
      "        S0011011C 4dc0cb821bca135bb0aefdb588f218ea152babc0536de3e6d577519d3fccc2c2\n",
      "        S0011011C 4dc0cb821bca135bb0aefdb588f218ea152babc0536de3e6d577519d3fccc2c2\n"
     ]
    }
   ],
   "source": [
    "def hash_resale_identifier(df):\n",
    "    df['Resale Identifier Hashed'] = df['Resale Identifier'].apply(\n",
    "        lambda x: hashlib.sha256(str(x).encode()).hexdigest()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df_hashed = hash_resale_identifier(df_transformed)\n",
    "\n",
    "path = os.path.join(HASHED_OUT_DIR, 'hdb_resale_hashed.csv')\n",
    "df_hashed.to_csv(path, index=False)\n",
    "print(f'üíæ Hashed dataset saved: {path}')\n",
    "print('\\nSample hashes:')\n",
    "print(df_hashed[['Resale Identifier','Resale Identifier Hashed']].head(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-4027741408498021158",
   "metadata": {},
   "source": [
    "## ‚úÖ ETL Complete ‚Äî Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "code-6556797434884807871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "‚úÖ HDB RESALE ETL PIPELINE COMPLETE\n",
      "============================================================\n",
      "  Final rows     : 87,346\n",
      "  Final columns  : 15\n",
      "  Date range     : 2012-03-01 ‚Üí 2016-12-01\n",
      "\n",
      "Output files:\n",
      "  ‚úì output\\raw\\hdb_resale_raw.csv\n",
      "  ‚úì output\\cleaned\\hdb_resale_cleaned.csv\n",
      "  ‚úì output\\transformed\\hdb_resale_transformed.csv\n",
      "  ‚úì output\\hashed\\hdb_resale_hashed.csv\n",
      "  ‚úì output\\failed\\hdb_resale_failed.csv\n",
      "  ‚úì output\\audit\\duplicates.csv\n",
      "  ‚ö†Ô∏è  output\\audit\\rule_violations.csv\n",
      "  ‚úì output\\audit\\anomalies.csv\n",
      "  ‚úì output\\profiling\\profile_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "print('=' * 60)\n",
    "print('‚úÖ HDB RESALE ETL PIPELINE COMPLETE')\n",
    "print('=' * 60)\n",
    "print(f'  Final rows     : {len(df_hashed):,}')\n",
    "print(f'  Final columns  : {len(df_hashed.columns)}')\n",
    "print(f'  Date range     : {df_hashed[\"month\"].min().date()} ‚Üí {df_hashed[\"month\"].max().date()}')\n",
    "print()\n",
    "print('Output files:')\n",
    "outputs = [\n",
    "    (RAW_OUT_DIR,       'hdb_resale_raw.csv'),\n",
    "    (CLEANED_OUT_DIR,   'hdb_resale_cleaned.csv'),\n",
    "    (TRANSFORM_OUT_DIR, 'hdb_resale_transformed.csv'),\n",
    "    (HASHED_OUT_DIR,    'hdb_resale_hashed.csv'),\n",
    "    (FAILED_OUT_DIR,    'hdb_resale_failed.csv'),\n",
    "    (AUDIT_OUT_DIR,     'duplicates.csv'),\n",
    "    (AUDIT_OUT_DIR,     'rule_violations.csv'),\n",
    "    (AUDIT_OUT_DIR,     'anomalies.csv'),\n",
    "    (PROFILE_OUT_DIR,   'profile_cleaned.csv'),\n",
    "]\n",
    "for folder, fname in outputs:\n",
    "    path = os.path.join(folder, fname)\n",
    "    status = '‚úì' if os.path.isfile(path) else '‚ö†Ô∏è '\n",
    "    print(f'  {status} {path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
